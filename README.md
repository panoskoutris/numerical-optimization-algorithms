# Numerical Optimization Algorithms

MATLAB implementations of numerical optimization algorithms, covering univariate, multivariate, and constrained optimization. Each part focuses on applying specific methods to minimize mathematical functions under various conditions and parameters.

Developed as part of the course *Optimization Techniques* at the Aristotle University of Thessaloniki (AUTH), School of Electrical & Computer Engineering.

---

## ğŸ“˜ Part 1: Univariate Optimization

**Goal:** Minimize three convex one-dimensional functions over fixed intervals using both derivative-free and derivative-based methods.

### ğŸ” Methods Implemented:
- **Bisection Method** (without derivative)
- **Bisection Method with derivative**
- **Golden Section Search**
- **Fibonacci Search**

### ğŸ§ª Applied To:
Each method is applied to three convex functions defined on an interval \([a, b]\), with varying:
- Interval tolerance `l`
- Accuracy parameter `Îµ`

### ğŸ”§ Tasks:
- Compare performance via iteration count and function evaluations
- Plot convergence behavior for all methods
- Analyze robustness and sensitivity to parameter choices

---

## ğŸ“˜ Part 2: Multivariate Optimization

**Goal:** Minimize the two-variable function:

`f(x, y) = x^5 Â· e^(âˆ’(xÂ² + yÂ²))`

### ğŸ” Methods Implemented:
- **Steepest Descent** (Gradient Descent)
- **Newton's Method**
- **Levenbergâ€“Marquardt Algorithm**

### ğŸš€ Initialization:
Each method is tested from different starting points:
- (0, 0)
- (âˆ’1, 1)
- (1, âˆ’1)

### ğŸ§­ Step Size Strategies:
- Fixed step size
- **Exact Line Search** using Bisection
- **Armijo Rule**

### ğŸ”§ Tasks:
- Evaluate convergence for each methodâ€“pointâ€“strategy combination
- Analyze convergence speed, stability, and optimization paths
- Visualize and interpret convergence surfaces and trajectories

---

## ğŸ“˜ Part 3: Constrained Optimization

**Goal:** Minimize a quadratic function under box constraints using a projected gradient approach.

### ğŸ“‰ Function:

`f(xâ‚, xâ‚‚) = (1/3)xâ‚Â² + 3xâ‚‚Â²`


### ğŸ“ Constraints (Box):
- âˆ’10Â â‰¤Â xâ‚Â â‰¤Â 5  
- 0Â â‰¤Â xâ‚‚Â â‰¤Â 10


### ğŸ” Method Implemented:
- **Projected Gradient Descent**
  - Uses projection operator Prâ‚“{Â·}  to enforce feasibility

### ğŸ§ª Experiments:
- Test with different step sizes `s` and interpolation factors `Î³`
- Explore behavior from different starting points (e.g. (4, 5), (5, âˆ’5), (âˆ’5, 10))
- Assess convergence, constraint satisfaction, and oscillatory behavior

### ğŸ§  Key Insight:
Stability depends on keeping *s Â· Î³*  below a theoretical threshold (e.g., less than 1/3)

---

## ğŸ“Š Tools and Languages

- MATLAB
- Symbolic Math Toolbox
- Plotting utilities for convergence and trajectory visualization

---

## ğŸ“ Repository Structure

```
numerical-optimization-algorithms
â”œâ”€â”€ part1-univariate-methods                  # Univariate unconstrained optimization algorithms and comparisons
â”‚   â”œâ”€â”€ src
â”‚   â”‚   â”œâ”€â”€ bisection_bounds.m                # Plots interval bounds [a_k, b_k] during bisection method iterations
â”‚   â”‚   â”œâ”€â”€ bisection_derivative_bounds.m     # Plots interval bounds [a_k, b_k] during bisection with derivative method iterations
â”‚   â”‚   â”œâ”€â”€ bisection_derivative_vs_l.m       # Compares evaluation count vs l for bisection method with derivative
â”‚   â”‚   â”œâ”€â”€ bisection_vs_e.m                  # Compares evaluation count vs Îµ for bisection method
â”‚   â”‚   â”œâ”€â”€ bisection_vs_l.m                  # Compares evaluation count vs l for bisection method
â”‚   â”‚   â”œâ”€â”€ fibonacci_bounds.m                # Plots interval bounds [a_k, b_k] during Fibonacci method iterations
â”‚   â”‚   â”œâ”€â”€ fibonacci_vs_l.m                  # Compares evaluation count vs l for Fibonacci method
â”‚   â”‚   â”œâ”€â”€ golden_section_bounds.m           # Plots interval bounds [a_k, b_k] during ggolden section method iterations
â”‚   â”‚   â”œâ”€â”€ golden_section_vs_l.m             # Compares evaluation count vs l for Golden Section method
â”‚   â””â”€â”€ report1.pdf                           # Report for Part 1
â”‚
â”œâ”€â”€ part2-multivariate-methods                # Multivariate (2-D) unconstrained optimization algorithms and comparisons
â”‚   â”œâ”€â”€ src
â”‚   â”‚   â”œâ”€â”€ armijo_rule.m                     # Implements Armijo line search rule
â”‚   â”‚   â”œâ”€â”€ bisection.m                       # Bisection search function for multivariate methods
â”‚   â”‚   â”œâ”€â”€ check_hessian_pos_def.m           # Checks whether the Hessian is positive definite at given points
â”‚   â”‚   â”œâ”€â”€ levenberg_marquardt.m             # Levenberg-Marquardt method function with multiple step strategies
â”‚   â”‚   â”œâ”€â”€ levenberg_marquardt_comparison.m  # Runs L-M with different Î³ rules and starting points and compares convergence
â”‚   â”‚   â”œâ”€â”€ newton.m                          # Newton's method function with optional Armijo or bisection line search
â”‚   â”‚   â”œâ”€â”€ steepest_descent.m                # Steepest descent with configurable Î³ (fixed, bisection, Armijo)
â”‚   â”‚   â”œâ”€â”€ steepest_descent_comparison.m     # Runs steepest descent with different Î³ rules and starting points and compares convergence
â”‚   â”‚   â”œâ”€â”€ visualize_function.m              # Plots 3D surface and contour of the main test function
â”‚   â””â”€â”€ report2.pdf                           # Report for Part 2
â”‚
â”œâ”€â”€ part3-projection-method                   # Multivariate box-constrained optimization algorithm and comparisons using projected method
â”‚   â”œâ”€â”€ src
â”‚   â”‚   â”œâ”€â”€ run_constrained_steepest_descent_1.m  # Steepest descent from xâ‚€ = [5; -5]
â”‚   â”‚   â”œâ”€â”€ run_constrained_steepest_descent_2.m  # Same method from xâ‚€ = [-5; 10]
â”‚   â”‚   â”œâ”€â”€ run_constrained_steepest_descent_3.m  # Same method from xâ‚€ = [8; -10]
â”‚   â”‚   â”œâ”€â”€ run_steepest_descent_vs_gamma.m       # Runs basic steepest descent with varying Î³ values 
â”‚   â”‚   â”œâ”€â”€ steepest_descent.m                    # Unconstrained steepest descent method function 
â”‚   â”‚   â”œâ”€â”€ steepest_descent_with_constraints.m   # Unconstrained steepest descent method function 
â”‚   â”‚   â”œâ”€â”€ visualize_function.m                  # Plots 2D quadratic test function 
â”‚   â””â”€â”€ report3.pdf                           # Report for Part 3
â”‚
â””â”€â”€ README.md                                 # Repository overview and instructions


```

---

## âœï¸ Author

**Panagiotis Koutris**  
Student at ECE AUTH â€“ School of Electrical & Computer Engineering

---

## ğŸ“„ License

This project is licensed under the [MIT License](https://opensource.org/licenses/MIT).

